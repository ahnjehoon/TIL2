{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential\n",
    "    - 딥러닝의 구조를 한 층 한 층 쉽게 쌓아올릴수 있게 해줌\n",
    "    - Sequential 함수 선언 후 model.add() 함수를 사용해 필요한 층을 차례로 추가해주면 됨\n",
    "* Dense\n",
    "    - model.add() 함수에는 Dense() 함수가 포함되어 있음 \n",
    "    - dense는 '조밀하게 모여있는 집합' 이라는 뜻으로 각 층이 제각각 어떤 특성을 가질지 옵션을 설정하는 역할을 함\n",
    "    - 딥러닝의 구조와 층별 옵션을 정하고 나면 compile() 함수를 사용해 이를 실행 시킴\n",
    "    - 예문\n",
    "        ```python\n",
    "        model.add(Dense(30, input_dim=17, activation='relu'))\n",
    "        model.add(Dense(1,activation='sigmoid'))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])    \n",
    "        ```\n",
    "    - 추후 나올 키워드들 미리 설명\n",
    "        1. activation\n",
    "            + 다음 층으로 어떻게 값을 넘길지 결정하는 부분\n",
    "            + relu와 sigmoid 함수를 자주 사용함\n",
    "        2. loss\n",
    "            + 한번 신경망이 실행될 때마다 오차 값을 추적하는 함수\n",
    "        3. optimizer\n",
    "            + 오차를 어떻게 줄여 나갈지 정하는 함수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 선형회귀\n",
    "\n",
    "## 1.1 선형회귀 정의\n",
    "* 구하고자 하는 값을 변화하게 하는 __요소__를 x라하고 이 x 값에 의해 변화하는 __구하고자 하는 값__을 y라 정의 해봄\n",
    "* 수식으로 나타내면 y = ax + b 여기서 a는 기울기 b는 절편\n",
    "* 여기서 x를 __독립변수__ y를 __종속변수__ 라고함\n",
    "* x가 하나면 __단순 선형회귀__(simple linear regression)\n",
    "* x가 여러개면 __다중 선형회귀__(multiple linear regression)\n",
    "\n",
    "### 1.2 최소 제곱법(method of least squares)\n",
    "* 선형회귀에서 목표는 __가장 정확한 직선__을 긋는 것\n",
    "* a = (x-x평균)(y-y평균)의 합 / (x-x평균)제곱의 합\n",
    "* b = y의 평균 - (x의 평균 * 기울기 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 평균값: 5.0\n",
      "y의 평균값: 90.5\n",
      "분모: 20.0\n",
      "분자: 46.0\n",
      "기울기 a = 2.3\n",
      "y 절편 b = 79.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "# x 값과 y값\n",
    "x=[2, 4, 6, 8]\n",
    "y=[81, 93, 91, 97]\n",
    "\n",
    "# x와 y의 평균값\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "print(\"x의 평균값:\", mx)\n",
    "print(\"y의 평균값:\", my)\n",
    "\n",
    "# 기울기 공식의 분모\n",
    "divisor = sum([(mx - i)**2 for i in x])\n",
    "\n",
    "# 기울기 공식의 분자\n",
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i] - my)\n",
    "    return d\n",
    "dividend = top(x, mx, y, my)\n",
    "\n",
    "print(\"분모:\", divisor)\n",
    "print(\"분자:\", dividend)\n",
    "\n",
    "# 기울기와 y 절편 구하기\n",
    "a = dividend / divisor\n",
    "b = my - (mx*a)\n",
    "\n",
    "# 출력으로 확인\n",
    "print(\"기울기 a =\", a)\n",
    "print(\"y 절편 b =\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 평균 제곱근 오차(root mean square error)\n",
    "* 독립변수가 하나일때는 최소 제곱법을 쓰면 되지만 여러개일때는 무작위로 값을 대입해야함\n",
    "* 독립변수가 두개 이상일 경우의 기울기와 b를 찾아낼때 오차를 조금씩 수정하기 위한 오차 평가 알고리즘\n",
    "* 실제값 - 예측값을 해서 오차값을 구한 후 부호제거를 위해 제곱한 후 평균을 구함. __평균 제곱 오차__(Mean Squared Error, MSE)\n",
    "* 이 평균 제곱 오차에 ROOT값을 씌우면 평균 제곱근 오차가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부시간=2, 실제점수=81, 예측점수=82\n",
      "공부시간=4, 실제점수=93, 예측점수=88\n",
      "공부시간=6, 실제점수=91, 예측점수=94\n",
      "공부시간=8, 실제점수=97, 예측점수=100\n",
      "rmse 최종값: 3.3166247903554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#기울기 a와 y 절편 b\n",
    "ab=[3,76]\n",
    "\n",
    "# x,y의 데이터 값\n",
    "data = [[2, 81], [4, 93], [6, 91], [8, 97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "# y=ax + b에 a,b 값 대입하여 결과를 출력하는 함수\n",
    "def predict(x):\n",
    "   return ab[0]*x + ab[1]\n",
    "\n",
    "# RMSE 함수\n",
    "def rmse(p, a):\n",
    "   return np.sqrt(((p - a) ** 2).mean())\n",
    "\n",
    "# RMSE 함수를 각 y값에 대입하여 최종 값을 구하는 함수\n",
    "def rmse_val(predict_result,y):\n",
    "   return rmse(np.array(predict_result), np.array(y))\n",
    "\n",
    "# 예측값이 들어갈 빈 리스트\n",
    "predict_result = []\n",
    "\n",
    "# 모든 x값을 한 번씩 대입하여 predict_result 리스트완성.\n",
    "for i in range(len(x)):\n",
    "   predict_result.append(predict(x[i]))\n",
    "   print(\"공부시간=%.f, 실제점수=%.f, 예측점수=%.f\" % (x[i], y[i], predict(x[i])))\n",
    "\n",
    "# 최종 RMSE 출력\n",
    "print(\"rmse 최종값: \" + str(rmse_val(predict_result,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 오차 수정하기: 경사 하강법\n",
    "\n",
    "## 2.1 경사 하강법 개요\n",
    "* a를 무한대로 키우면 오차도 무한대로 커지고\n",
    "* a를 무한대로 작게 해도 오차가 무한대로 커짐\n",
    "* 적절한 a를 구하는게 필요함\n",
    "* 이때 미분을 이용하여 순간기울기가 0인 지점을 찾는것이 목적\n",
    "* 즉 경사하강법의 순서는 아래와 같음\n",
    "    1. a1에서 미분을 구함\n",
    "    2. 구해진 기울기의 반대방향(기울기가 + 면 음의 방향, -면 양의방향)으로 얼마간 이동시킨 a2에서 미분을 구함\n",
    "    3. a3에서 미분을 구함\n",
    "    4. 3의 값이 0이 아니면 위의 과정을 반복함\n",
    "    \n",
    "## 2.2 학습률(learning rate)\n",
    "* 기울기의 부호를 바꿔 이동시킬 때 이동 거리를 정해주는 것\n",
    "* 케라스는 학습률을 자동으로 조절해준다함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch: 0, RMSE = 30.2139, 기울기 a = 7.5235, y 절편 b = 80.5984\n",
      "Epoch: 100, RMSE = 2.8860, 기울기 a = 2.2299, y 절편 b = 79.4181\n",
      "Epoch: 200, RMSE = 2.8826, 기울기 a = 2.2601, y 절편 b = 79.2379\n",
      "Epoch: 300, RMSE = 2.8815, 기울기 a = 2.2773, y 절편 b = 79.1353\n",
      "Epoch: 400, RMSE = 2.8811, 기울기 a = 2.2871, y 절편 b = 79.0770\n",
      "Epoch: 500, RMSE = 2.8810, 기울기 a = 2.2927, y 절편 b = 79.0438\n",
      "Epoch: 600, RMSE = 2.8810, 기울기 a = 2.2958, y 절편 b = 79.0249\n",
      "Epoch: 700, RMSE = 2.8810, 기울기 a = 2.2976, y 절편 b = 79.0142\n",
      "Epoch: 800, RMSE = 2.8810, 기울기 a = 2.2987, y 절편 b = 79.0081\n",
      "Epoch: 900, RMSE = 2.8810, 기울기 a = 2.2992, y 절편 b = 79.0046\n",
      "Epoch: 1000, RMSE = 2.8810, 기울기 a = 2.2996, y 절편 b = 79.0026\n",
      "Epoch: 1100, RMSE = 2.8810, 기울기 a = 2.2998, y 절편 b = 79.0015\n",
      "Epoch: 1200, RMSE = 2.8810, 기울기 a = 2.2999, y 절편 b = 79.0008\n",
      "Epoch: 1300, RMSE = 2.8810, 기울기 a = 2.2999, y 절편 b = 79.0005\n",
      "Epoch: 1400, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0003\n",
      "Epoch: 1500, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0002\n",
      "Epoch: 1600, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0001\n",
      "Epoch: 1700, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0001\n",
      "Epoch: 1800, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0000\n",
      "Epoch: 1900, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0000\n",
      "Epoch: 2000, RMSE = 2.8810, 기울기 a = 2.3000, y 절편 b = 79.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# x, y의 데이터 값\n",
    "data = [[2, 81], [4, 93], [6, 91], [8, 97]]\n",
    "x_data = [x_row[0] for x_row in data]\n",
    "y_data = [y_row[1] for y_row in data]\n",
    "\n",
    "# 기울기 a와 y 절편 b의 값을 임의로 정한다.\n",
    "# 단, 기울기의 범위는 0 ~ 10 사이이며 y 절편은 0 ~ 100 사이에서 변하게 한다.\n",
    "a = tf.Variable(tf.random_uniform([1], 0, 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype = tf.float64, seed = 0))\n",
    "\n",
    "# y에 대한 일차 방정식 ax+b의 식을 세운다.\n",
    "y = a * x_data + b\n",
    "\n",
    "# 텐서플로 RMSE 함수\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# 학습률 값\n",
    "learning_rate = 0.1\n",
    "\n",
    "# RMSE 값을 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 텐서플로를 이용한 학습\n",
    "with tf.Session() as sess:\n",
    "    # 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 2001번 실행(0번 째를 포함하므로)\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_decent)\n",
    "        # 100번마다 결과 출력\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, 기울기 a = %.4f, y 절편 b = %.4f\" % (step,sess.run(rmse),sess.run(a),sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 다중 선형 회귀\n",
    "* 이전에 봤던 선형회귀는 독립변수를 하나만 사용했지만 얜 두개 이상임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE = 49.1842, 기울기 a1 = 7.5270, 기울기 a2 = 7.8160, y절편 b = 80.5980\n",
      "Epoch: 100, RMSE = 1.8368, 기울기 a1 = 1.1306, 기울기 a2 = 2.1316, y절편 b = 78.5119\n",
      "Epoch: 200, RMSE = 1.8370, 기울기 a1 = 1.1879, 기울기 a2 = 2.1487, y절편 b = 78.1057\n",
      "Epoch: 300, RMSE = 1.8370, 기울기 a1 = 1.2122, 기울기 a2 = 2.1571, y절편 b = 77.9352\n",
      "Epoch: 400, RMSE = 1.8370, 기울기 a1 = 1.2226, 기울기 a2 = 2.1607, y절편 b = 77.8636\n",
      "Epoch: 500, RMSE = 1.8370, 기울기 a1 = 1.2269, 기울기 a2 = 2.1622, y절편 b = 77.8335\n",
      "Epoch: 600, RMSE = 1.8370, 기울기 a1 = 1.2288, 기울기 a2 = 2.1628, y절편 b = 77.8208\n",
      "Epoch: 700, RMSE = 1.8370, 기울기 a1 = 1.2295, 기울기 a2 = 2.1631, y절편 b = 77.8155\n",
      "Epoch: 800, RMSE = 1.8370, 기울기 a1 = 1.2299, 기울기 a2 = 2.1632, y절편 b = 77.8133\n",
      "Epoch: 900, RMSE = 1.8370, 기울기 a1 = 1.2300, 기울기 a2 = 2.1632, y절편 b = 77.8124\n",
      "Epoch: 1000, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8120\n",
      "Epoch: 1100, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8118\n",
      "Epoch: 1200, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1300, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1400, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1500, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1600, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1700, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1800, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1900, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 2000, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# x1, x2, y의 데이터 값\n",
    "\n",
    "data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]\n",
    "x1 = [x_row1[0] for x_row1 in data]\n",
    "x2 = [x_row2[1] for x_row2 in data] # 새로 추가되는 값\n",
    "y_data = [y_row[2] for y_row in data]\n",
    "\n",
    "# 기울기 a와 y절편 b의 값을 임의로 정함. 단 기울기의 범위는 0-10 사이, y 절편은 0-100사이에서 변하게 함\n",
    "a1 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "a2 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
    "\n",
    "# 새로운 방정식\n",
    "y = a1 * x1 + a2 * x2+ b\n",
    "\n",
    "# 텐서플로 RMSE 함수\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# 학습률 값\n",
    "learning_rate = 0.1\n",
    "\n",
    "# RMSE 값을 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 학습이 진행되는 부분\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_decent)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, 기울기 a1 = %.4f, 기울기 a2 = %.4f, y절편 b = %.4f\" % (step,sess.run(rmse),sess.run(a1),sess.run(a2),sess.run(b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 로지스틱 회귀\n",
    "* 종속변수가 명목형(Yes, No 같이 수치형이 아님)일때 사용하는 방법"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
