{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    # df['date'] = df['date'].apply(lambda x: x[0:8])\n",
    "    # 일짜까지 되있는걸 월까지\n",
    "    df['date'] = df['date'].apply(lambda x: x[0:6])\n",
    "    df['data_y'] = ''\n",
    "    df['data_m'] = ''\n",
    "    df['data_y'] = df['date'].apply(lambda x : x[0:4])\n",
    "    df['data_m'] = df['date'].apply(lambda x : x[4:6])\n",
    "    df['yr_renovated'] = df['yr_renovated'].apply(lambda x: np.nan if x == 0 else x)\n",
    "    df['yr_renovated'] = df['yr_renovated'].fillna(df['yr_built'])\n",
    "for df in [df_train]:\n",
    "    # 1000단위 대로 반올림\n",
    "    df['price'] = df['price'].apply(lambda x: round(x, -3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "    df['sqft_ratio'] = df['sqft_living'] / df['sqft_lot']\n",
    "    df['sqft_total_size'] = df['sqft_above'] + df['sqft_basement']\n",
    "    df['sqft_ratio15'] = df['sqft_living15'] / df['sqft_lot15'] \n",
    "    df['is_renovated'] = df['yr_renovated'] - df['yr_built']\n",
    "    df['is_renovated'] = df['is_renovated'].apply(lambda x: 0 if x == 0 else 1)\n",
    "    df['date'] = df['date'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['per_price'] = df_train['price']/df_train['sqft_total_size']\n",
    "zipcode_price = df_train.groupby(['zipcode'])['per_price'].agg({'mean','var'}).reset_index()\n",
    "df_train = pd.merge(df_train,zipcode_price,how='left',on='zipcode')\n",
    "df_test = pd.merge(df_test,zipcode_price,how='left',on='zipcode')\n",
    "\n",
    "for df in [df_train,df_test]:\n",
    "    df['mean'] = df['mean'] * df['sqft_total_size']\n",
    "    df['var'] = df['var'] * df['sqft_total_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라벨 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# LE = LabelEncoder()\n",
    "# LE.fit(df_train[['date']])\n",
    "# df_train[['date']] = LE.transform(df_train[['date']])\n",
    "# LE.fit(df_train[['zipcode']])\n",
    "# df_train[['zipcode']] = LE.transform(df_train[['zipcode']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상호작용변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geogege(data):\n",
    "    data['zipcode'] = data['zipcode'].astype(str)  \n",
    "    data['zipcode-3'] = data['zipcode'].apply(lambda x : str(x[2:3])).astype(int)\n",
    "    data['zipcode-4'] = data['zipcode'].apply(lambda x : str(x[3:4])).astype(int)\n",
    "    data['zipcode-5'] = data['zipcode'].apply(lambda x : str(x[4:5])).astype(int)\n",
    "    data['zipcode-34'] = data['zipcode'].apply(lambda x : str(x[2:4])).astype(int)\n",
    "    data['zipcode-45'] = data['zipcode'].apply(lambda x : str(x[3:5])).astype(int)\n",
    "    data['zipcode-35'] = data['zipcode'].apply(lambda x : str(x[2:5])).astype(int)\n",
    "#     data.drop('zipcode', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppcca1(data):\n",
    "    pca2 = PCA(n_components=2)\n",
    "    coord_test = data[['lat','long']]\n",
    "    \n",
    "    principalComponents_updated_test = pca2.transform(coord_test)\n",
    "    data['coord_pca1']= ''\n",
    "    data['coord_pca2']= ''\n",
    "    data['coord_pca1']= principalComponents_updated_test[:, 0]\n",
    "    data['coord_pca2']= principalComponents_updated_test[:, 1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppcca2(data):\n",
    "    pca1 = PCA(n_components=2)\n",
    "\n",
    "    principalComponents_updated_test = pca1.transform(data)\n",
    "    data['pca1']= ''\n",
    "    data['pca2']= ''\n",
    "    data['pca1']= principalComponents_updated_test[:, 0]\n",
    "    data['pca2']= principalComponents_updated_test[:, 1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_length = len(df_train)\n",
    "concat_dataset = pd.concat(objs=[df_train, df_test], axis=0)\n",
    "\n",
    "# ZIP divide\n",
    "concat_dataset = geogege(concat_dataset)\n",
    "\n",
    "# LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "# LE.fit(df_train[['date']])\n",
    "# concat_dataset[['date']] = LE.transform(concat_dataset[['date']])\n",
    "# LE.fit(df_train[['zipcode']])\n",
    "# concat_dataset[['zipcode']] = LE.transform(concat_dataset[['zipcode']])\n",
    "concat_dataset['date_zipcode'] = concat_dataset['date'].map(str) + \"_\" + concat_dataset['zipcode'].map(str)\n",
    "LE.fit(concat_dataset[['date_zipcode']])\n",
    "concat_dataset[['date_zipcode']] = LE.transform(concat_dataset[['date_zipcode']])\n",
    "\n",
    "# PCA\n",
    "# concat_dataset = ppcca1(concat_dataset)\n",
    "# concat_dataset = ppcca2(concat_dataset)\n",
    "\n",
    "df_train = concat_dataset[:df_train_length]\n",
    "df_test = concat_dataset[df_train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = concat_dataset[concat_dataset.columns.difference(['per_price','price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15035, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 월별 + ZIPCODE를 활용한 더미변수 추가하여 테스트\n",
    "위도 + 경도로 위치값을 대신하고 싶었지만 어떻게 구역을 나눠야 할지 모르기때문에 ZIPCODE로 대신함"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train_length = len(df_train)\n",
    "concat_dataset = pd.concat(objs=[df_train, df_test], axis=0)\n",
    "\n",
    "concat_dataset['date_zipcode'] = concat_dataset['date'].map(str) + \"_\" + concat_dataset['zipcode'].map(str)\n",
    "dataset_preprocessed = pd.get_dummies(concat_dataset, columns=['date', 'zipcode','date_zipcode'])\n",
    "\n",
    "df_train = dataset_preprocessed[:df_train_length]\n",
    "df_test = dataset_preprocessed[df_train_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "import xgboost as xgb\n",
    "\n",
    "train_columns = [c for c in df_train.columns if c not in ['id','price','per_price']]\n",
    "y_reg = df_train['price']\n",
    "\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'learning_rate': 0.01\n",
    "    ,'n_estimators': 10000\n",
    "    ,'max_depth': 7\n",
    "    ,'subsample': 0.9\n",
    "    ,'num_boost_round': 3000\n",
    "    ,'early_stopping_rounds': 500\n",
    "#     ,'eval_metric': 'rmse'\n",
    "#     ,'objective': 'reg:linear'\n",
    "    ,'seed': 2019\n",
    "}\n",
    "\n",
    "model= xgb.XGBRegressor(\n",
    "    # eta [default=0.3, alias: learning_rate] 학습율\n",
    "    learning_rate=0.005,\n",
    "    # 모형 갯수 default=100\n",
    "    n_estimators=80001,\n",
    "    random_state=2019,\n",
    "    # 학습 횟수\n",
    "    num_boost_round=10000, \n",
    "    # overfitting 방지\n",
    "    early_stopping_rounds=5,\n",
    "    verbose_eval=3000, \n",
    "    show_stdv=False,\n",
    "    max_depth=7, \n",
    "    nthread=-1,\n",
    "    tree_method='gpu_hist'\n",
    ")\n",
    "\n",
    "#prepare fit model with cross-validation\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train)):\n",
    "    X_train,X_validation=df_train.iloc[trn_idx][train_columns],df_train.iloc[val_idx][train_columns]\n",
    "    y_train,y_validation=y_reg.iloc[trn_idx],y_reg.iloc[val_idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    dtarget=xgb.DMatrix(y_train)\n",
    "    dtest = xgb.DMatrix(X_validation)\n",
    "    dtest_target=xgb.DMatrix(y_validation)\n",
    "    \n",
    "    model.fit(X_train,y_train\n",
    "              ,eval_set=[(X_train,y_train),(X_validation,y_validation)]\n",
    "              ,eval_metric='rmse'\n",
    "              # log 얼마단위로 찍을건지\n",
    "              ,verbose=2000\n",
    "             )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model= xgb.XGBRegressor(\n",
    "    tree_method='gpu_hist',\n",
    "    n_estimators=100000,\n",
    "    num_round_boost=500,\n",
    "    show_stdv=False,\n",
    "    feature_selector='greedy',\n",
    "    verbosity=0,\n",
    "    reg_lambda=10,\n",
    "    reg_alpha=0.01,\n",
    "    learning_rate=0.001,\n",
    "    seed=42,\n",
    "    colsample_bytree=0.8,\n",
    "    colsample_bylevel=0.8,\n",
    "    subsample=0.8,\n",
    "    n_jobs=-1,\n",
    "    gamma=0.005,\n",
    "    base_score=np.mean(y_target)\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train, verbose=False, eval_set=watchlist,\n",
    "              eval_metric='rmse',\n",
    "              early_stopping_rounds=1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score=mse(np.exp(model.predict(X_test)),np.exp(y_test))**0.5\n",
    "pred=np.exp(model.predict(Y_test))\n",
    "\n",
    "print(\"RMSE unseen : {}\".format(xgb_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
