{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
       "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_train.iloc[:,[1]], df_train.iloc[:,3:21]], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['201410', '201502', '201406', '201501', '201504', '201405',\n",
       "       '201503', '201407', '201412', '201408', '201411', '201409',\n",
       "       '201505'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 날짜값 변경\n",
    "def datePreprocessing(text):\n",
    "    return text[0:6]\n",
    "df_train['date'] = df_train['date'].apply(datePreprocessing)\n",
    "\n",
    "# 제대로 됬나 확인\n",
    "df_train['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(pd.concat([df_train.iloc[:,[1]], df_train.iloc[:,3:21]], axis=1))\n",
    "y = df_train.iloc[:,[2]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7021656626159374"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\t#초기화\n",
    "lm.fit(X_train,y_train)\t#학습\n",
    "lm.coef_\t#가중치확인\n",
    "lm.intercept_\t#절편확인\n",
    "lm.score(X_train,y_train)\t#결정계수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['date'] = df['date'].apply(lambda x: x[0:8])\n",
    "    df['yr_renovated'] = df['yr_renovated'].apply(lambda x: np.nan if x == 0 else x)\n",
    "    df['yr_renovated'] = df['yr_renovated'].fillna(df['yr_built'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "    df['sqft_ratio'] = df['sqft_living'] / df['sqft_lot']\n",
    "    df['sqft_total_size'] = df['sqft_above'] + df['sqft_basement']\n",
    "    df['sqft_ratio15'] = df['sqft_living15'] / df['sqft_lot15'] \n",
    "    df['is_renovated'] = df['yr_renovated'] - df['yr_built']\n",
    "    df['is_renovated'] = df['is_renovated'].apply(lambda x: 0 if x == 0 else 1)\n",
    "    df['date'] = df['date'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['per_price'] = df_train['price']/df_train['sqft_total_size']\n",
    "zipcode_price = df_train.groupby(['zipcode'])['per_price'].agg({'mean','var'}).reset_index()\n",
    "df_train = pd.merge(df_train,zipcode_price,how='left',on='zipcode')\n",
    "df_test = pd.merge(df_test,zipcode_price,how='left',on='zipcode')\n",
    "\n",
    "for df in [df_train,df_test]:\n",
    "    df['mean'] = df['mean'] * df['sqft_total_size']\n",
    "    df['var'] = df['var'] * df['sqft_total_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.955\n",
      "Model:                            OLS   Adj. R-squared:                  0.955\n",
      "Method:                 Least Squares   F-statistic:                 1.386e+04\n",
      "Date:                Sat, 06 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        18:17:26   Log-Likelihood:            -1.9939e+05\n",
      "No. Observations:               15035   AIC:                         3.988e+05\n",
      "Df Residuals:                   15012   BIC:                         3.990e+05\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "date               85.2843     11.462      7.440      0.000      62.817     107.752\n",
      "bedrooms        -2.148e+04   1575.717    -13.633      0.000   -2.46e+04   -1.84e+04\n",
      "bathrooms        1.942e+04   2019.102      9.616      0.000    1.55e+04    2.34e+04\n",
      "sqft_living       -50.1773      1.588    -31.592      0.000     -53.291     -47.064\n",
      "sqft_lot            0.2610      0.039      6.612      0.000       0.184       0.338\n",
      "floors          -2.593e+04   3581.103     -7.241      0.000    -3.3e+04   -1.89e+04\n",
      "waterfront       6.238e+05   1.48e+04     42.141      0.000    5.95e+05    6.53e+05\n",
      "view             4.848e+04   1776.700     27.288      0.000     4.5e+04     5.2e+04\n",
      "condition        1.791e+04   1972.288      9.083      0.000     1.4e+04    2.18e+04\n",
      "grade            5.063e+04   1815.142     27.893      0.000    4.71e+04    5.42e+04\n",
      "sqft_above         10.2587      1.965      5.221      0.000       6.407      14.110\n",
      "sqft_basement     -60.4360      2.185    -27.659      0.000     -64.719     -56.153\n",
      "yr_built         -156.7834    232.991     -0.673      0.501    -613.475     299.908\n",
      "yr_renovated     -189.5940    237.579     -0.798      0.425    -655.278     276.090\n",
      "zipcode          -154.7595     26.362     -5.871      0.000    -206.432    -103.087\n",
      "lat             -2.177e+04   1.03e+04     -2.104      0.035    -4.2e+04   -1487.398\n",
      "long             4422.4273   1.12e+04      0.393      0.694   -1.76e+04    2.65e+04\n",
      "sqft_living15      25.6157      3.007      8.518      0.000      19.721      31.510\n",
      "sqft_lot15         -0.1675      0.062     -2.698      0.007      -0.289      -0.046\n",
      "total_rooms     -2065.1951    966.972     -2.136      0.033   -3960.577    -169.813\n",
      "sqft_ratio      -9.721e+04   9564.220    -10.164      0.000   -1.16e+05   -7.85e+04\n",
      "sqft_total_size   -50.1773      1.588    -31.592      0.000     -53.291     -47.064\n",
      "sqft_ratio15     6.102e+04   1.04e+04      5.882      0.000    4.07e+04    8.13e+04\n",
      "is_renovated     3.905e+04   1.43e+04      2.739      0.006    1.11e+04     6.7e+04\n",
      "mean                1.0714      0.014     76.094      0.000       1.044       1.099\n",
      "var                -0.0013      0.000     -4.232      0.000      -0.002      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                    11174.769   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1218161.494\n",
      "Skew:                           2.814   Prob(JB):                         0.00\n",
      "Kurtosis:                      46.736   Cond. No.                     1.35e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.87e-14. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "train_columns = [c for c in df_train.columns if c not in ['id','price','per_price']]\n",
    "\n",
    "model = sm.OLS(df_train['price'].values, df_train[train_columns])\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.015,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4950}\n",
    "\n",
    "y_reg = df_train['price']\n",
    "\n",
    "#prepare fit model with cross-validation\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "#run model\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train)):\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][train_columns], label=y_reg.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][train_columns], label=y_reg.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 100)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    #feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = train_columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    #predictions\n",
    "    predictions += clf.predict(df_test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "cv = np.sqrt(mean_squared_error(oof, y_reg))\n",
    "print(cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
