{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['id', 'price'], axis=1)\n",
    "y_train = np.log1p(df_train['price'])\n",
    "X_test = df_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding features\n",
    "for df in [X_train, X_test]:\n",
    "    df['date(new)'] = df['date'].apply(lambda x: int(x[4:8])+800 if x[:4] == '2015' else int(x[4:8])-400)\n",
    "    df['how_old'] = df['date'].apply(lambda x: x[:4]).astype(int) - df[['yr_built', 'yr_renovated']].max(axis=1)\n",
    "    del df['date']\n",
    "    del df['yr_renovated']\n",
    "    df['yr_built'] = df['yr_built'] - 1900\n",
    "    df['sqft_floor'] = df['sqft_above'] / df['floors']\n",
    "    df['floor_area_ratio'] = df['sqft_living'] / df['sqft_lot']\n",
    "    del df['sqft_lot15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Scaling\n",
    "log_features = ['bedrooms', 'bathrooms', 'sqft_lot', 'sqft_living', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_floor', 'floor_area_ratio', 'floor_area_ratio']\n",
    "for feature in log_features:\n",
    "    for df in [X_train, X_test]:\n",
    "        df[feature] = np.log1p(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feval function에 사용하기 위해\n",
    "def rmse_exp(predictions, dmat):\n",
    "    labels = dmat.get_label()\n",
    "    error = np.expm1(predictions) - np.expm1(labels)\n",
    "    squared_error = np.square(error)\n",
    "    mean = np.mean(squared_error)\n",
    "    return ('rmse_exp', np.sqrt(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate':[0.01, 0.05, 0.1]\n",
    "    ,'n_estimators':[10000]\n",
    "    ,'num_boost_round':[30, 50, 100]  # 100 ej\n",
    "    ,'early_stopping_rounds':[5, 10] # 10\n",
    "    ,'max_depth':[7,8]\n",
    "    ,'objective': ['reg:linear']\n",
    "    ,'eval_metric': ['rmse']\n",
    "    ,'silent': [True]\n",
    "    ,'seed': [2019]\n",
    "    ,'subsample':[0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 178.0min\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed: 195.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [10000], 'num_boost_round': [30, 50, 100], 'early_stopping_rounds': [5, 10], 'max_depth': [7, 8], 'objective': ['reg:linear'], 'eval_metric': ['rmse'], 'silent': [True], 'seed': [2019], 'subsample': [0.7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(xgb_model\n",
    "                   ,params\n",
    "                   ,n_jobs=4\n",
    "                   ,cv=5\n",
    "                   ,verbose=2, refit=True)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, early_stopping_rounds=5, eval_metric='rmse',\n",
      "       gamma=0, importance_type='gain', learning_rate=0.01,\n",
      "       max_delta_step=0, max_depth=7, min_child_weight=1, missing=None,\n",
      "       n_estimators=10000, n_jobs=1, nthread=None, num_boost_round=30,\n",
      "       objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2019, silent=True, subsample=0.7)\n"
     ]
    }
   ],
   "source": [
    "best_est = clf.best_estimator_\n",
    "print(best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate':[0.01, 0.05, 0.1]\n",
    "    ,'n_estimators':[10000]\n",
    "    ,'num_boost_round':[30, 50, 100]  # 100 ej\n",
    "    ,'early_stopping_rounds':[5, 10] # 10\n",
    "    ,'max_depth':[7,8]\n",
    "    ,'objective': ['reg:linear']\n",
    "    ,'eval_metric': ['rmse']\n",
    "    ,'silent': [True]\n",
    "    ,'seed': [2019]\n",
    "    ,'subsample':[0.7]\n",
    "}\n",
    "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, early_stopping_rounds=5, eval_metric='rmse',\n",
    "       gamma=0, importance_type='gain', learning_rate=0.01,\n",
    "       max_delta_step=0, max_depth=7, min_child_weight=1, missing=None,\n",
    "       n_estimators=10000, n_jobs=1, nthread=None, num_boost_round=30,\n",
    "       objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=2019, silent=True, subsample=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
