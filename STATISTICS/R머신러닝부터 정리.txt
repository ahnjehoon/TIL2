하면 좋을것들 정리
  강화학습 관련 강의보기
  멀캠에서 나눠준 책보기
  여태까지 배운거 정리하기
  아이디어 탐색(이건 자면서)
  탐색한 아이디어 구현하기
  
목차
  R기초문법정리
  시각화
  데이터 가공
  분석
  확률과 통계
  머신러닝
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
R기초 문법 정리

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
시각화
plot
  갖가지 유형에 대한 시각화를 제공함
  plot(x, y)
  옵션
    pch: 모양 ex20 색칠된원, 21 걍원
	cex: 크기
	col: 색상
  abline: 기울기
    abline(x,y)
    옵션
      col: 색상
	  lwd: 두께
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
데이터 가공
XML
  library(XML)	#XML 문서 파싱하는데 사용 ex)xmlTreeParse, xmlRoot
  library(RCurl)	#URL활용하여 웹문서 가져올때 사용 ex)getURL
  my_doc <- xmlTreeParse(getURL(URL주소),useInternalNodes=T) #useInternalNode는 잡다한거 져오니 T로 해놓자
  rootNode <- xmlRoot(my_doc) #XML데이터 상 맨위에 <?XML 어쩌구 하는 XML 문서 형태를 적어주는게 있는데 그거 제거해줌
  # XML문서에 접근할때
  rootNode[[1]] #첫째 노드
  rootNode[[2]][['name']][[1]] #두번째 노드에서 태그이름이 name인 텍스트 가져옴
  #매칭되는 속성값들을 가져옴. 여기선 name태그 값들
  xpathSApply(rootNode, "//name", xmlValue)
JSON #my_json이라는 json데이터를 가진 변수가 있다 가정함
  library(jsonlite)
  my_json <- fromJSON(URL) #JSON데이터를 가져옴
  colnames(my_json) #my_json의 key값들을 가져옴
  my_json<-toJSON(iris, pretty=TRUE) #iris 데이터를 JSON형태로 가독성있게 변환
  formJSON(my_json) #JSON객체를 데이터 프레임으로 변환
  save(my_json2, file="./my_json2") #JSON객체를 외부파일에 저장
  load("my_json2") #JSON파일 불러옴
HTML TEXT 크롤링
  #연합뉴스 속보 가져온다고 가정함 type01은 핫키워드 type02는 새로운 속보들인듯?
  library(httr)
  library(rvest)
  url <- "https://news.naver.com/main/list.nhn?mode=LPOD&mid=sec&sid1=001&sid2=140&oid=001&isYeonhapFlash=Y"
  GET(url) %>% read_html %>% html_nodes(".type02 li a strong") %>% html_text
DB연결 이건 걍 ex0104보셈 안쓸거같음
데이터
  데이터 변형
    데이터가 tidy하면 좋은점
	  일관성 유지
	  모든 R함수에서 열(column)=변수(variable), 행(row)=관측치(observation)라는 룰 적용
	데이터가 tidyㅘ지 않은 경우
       하나의 변수가 여러 열(column)에 걸쳐서 표현. gather() 또는 melt() 적용
	   하나의 관측치가 여러 행(row)에 걸쳐 표현. spread() 적용
	   하나의 셀에 여러값 존재. separate() 적용
	********** 데이터 획득과 가공 2-5에서 멈춤
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
머신러닝
  통계 모형과 데이터를 사용한 학습과 예측
  모형 자체는 단순하지만 패턴이 담긴 데이터를 학습하여 복잡한 예측이 가능
종류
  지도학습: 학습목표가 분명
  비지도학습: 스스로 패턴을 밝혀냄
  강화학습: 최적의 정책을 학습. 강화학습 관련해서는 깊게 들어가지 않음
    마르코프 의사결정 과정(Markov Decision Process)에 기반
	에이전트, 보상, 상태, 환경, 행동, 정책 개념이 있음
	에이전트는 현 상태에서 취할 수 있는 행동 중 보상을 최대화하는 쪽을 선택함
지도학습
  학습이란 암기한 내용을 똑같이 되새김 하는 것이 아닌 현실에 적용할 수 있도록 일반화가 검증되어야 함
  여기서 일반화란 어떤 데이터가 주어졌을때 그 데이터로 결과물을 내는 수식같은 개념인듯
  학습(train)과 시험(test)
    일반화를 검증하기 위해 학습(train)된 모형을 시험(test)함
	시험의 결과는 '오류'로 평가
    오류의 유형
	  편향오류(bias error)와 과소적합 오류(underfitting error)
	    모형이 편향적. 과하게 단순해서 발생하는 오류의 유형
		복잡성이 증가할수록 줄일 수 있음
	  분산오류(variance error)와 과적합 오류(overfitting error)
	    모형이 넘모 복잡해서 발생
		많이 학습시켜 줄일 수 있음
	  편향오류와 분산에러로 인한 TOTAL 오류를 줄이는게 최종 목표
선형회귀
  구성요소
    한개 이상의 독립변수(설명변수): X1, X2, ... Xk
	한 개의 종속변수: Y
	선형 조합(베타 계수 표기): Y= 베타0(절편.기본값.Intercept) + 베타1X1 + 베타2X2 .... 베타kXk + 오차
  목적: 독립변수X들을 통해 종속변수Y의 값을 구하는데 씀
  방법: 독립변수X에 계수(베타, 가중치?)를 곱함.
  주의점: 
    예를들어 독립변수X1과 X2와의 관련이 클때(상관계수가 높다라고함) 선형회귀의 수식에 안좋은 영향을 미침. 이경우 공선성이 높다함 ex) 키와 몸무게
	위와같은 공선성은 회귀계수의 표준오차를 증가시킴
  관련함수
    lm(); 선형회귀 모양을 만듦
	predict(): 설명변수에 반응한 종속변수의 값을 계산
	summary(): 선형회귀 모형의 세부 결과를 보여줌
	coefficients(): 
	---------------하다말았따 
	
	
	
	
시계열
  시간 기준으로 정렬된 수치 데이터
  표기방법: x1, x2, x3, --- Xt
  ex)특정기간의 주식 가격, 하루의 최고와 최저기온 등등
  구분
    정상 시계열(Stationary Time Series)
	약정상 시계열(Weak Stationary Time Series)
	비정상 시계열(Non Stationary Time Series)
  정상 시계열
    시간이 지나도 모든 확률성 특성이 그대로 유지되는 시계열
	너무 엄격한 조건이므로 약정상성으로 완화시킴
	AR, MA, ARMA, VAR, VECM등 모형을 적용하며 자기상관성에 기반
  약정상 시계열
    평균, 분산, 자기상관계수가 유지됨 ex)수익률
  비정상 시계열
    시간이 지나면 확률성 특성이 유지되지 않음
	시계열에 추세성 요소(trend)가 있음
	차분 연산자 적용으로 정상화: ARIMA 모형
	주식가격시계열같은경우 로그 수익률 시계열로 변환 후 정상시계열 모형 적용

  자기공분산함수(Auto-Convariance Function) & 자기상관계수(Auto-Correlation Function) ACF
	
  AR (Auto Regressive model) 자기 회귀 시계열 보형
    -p시점 전의 자료가 현자 자료에 영향을 줌
    AR(1)
	  현재의 값 xt가 1스텝 이전의 값 xt-1과 연관됨
	  즉 1시점 전에 의해 현재시점이 영향을 받는 모형
	  불확실 요소 앱실론t를 'impact' 또는 'innovation' 이라고 부름
	  앱실론t는 정규확률분포를 따른다는 가정
	  
  예측 방법
    지수 평활화 방법: Xt = 이동평균선t-1 추세t-1 + 불확실성t
	
Keras
  Keras: 모델 레벨의 하이엔드 딥러닝 라이브러리
    CUDA프로그래밍 하려면 매우어려움
    TensorFlow보다 사용하기 쉬운 C언어보단 JAVA의 느낌?인 언어
  TensorFlow: 머신러닝 또는 딥러닝 용도 라이브러리
    수치 연산을 표현한 Graph 구조를 만들고 처리
    다양한 OS와 언어를 지원하며 CPU, GPU 장점 모두 사용 가능
  배치학습
    데이터 전체를 한번에 사용하는게 아닌 작은 크기의 배치(batch)로 나누어서 학습함
    배치의 크기는 2~32면 좋음
    비교적 작은 배치를 사용하면 학습이 효율적
    적당한 gradient(방향) learning rate(거리)와 epoch(얼마나 많이?)가 적절해야됨. 넘 대충하면 결과물이 이상하고 넘 작게하면 시간이 오래걸리니깐
    Q 랜덤하게 뽑아온다면 학습시킬때마다 그럼 결과가 달라짐?
  Keras 학습 및 예측 순서
    모형의 layer 구조를 정의함
    손실함수와 최적화 방법을 정의하며 모형을 컴파일
    배치학습 방법을 정의하여 모형의 학습을 진행
    학습이 완료된 모형을 사용하여 예측
  R keras 설치
    install.packages("keras")
    library(keras)
    install_keras()
  R keras GPU활용 anaconda설치 가정
    library(keras)
    install_keras()
    install_keras(method = "conda")
    install_keras(tensorflow = "gpu")
    install.packages("tensorflow")
    # CUDA 9버전 설치 및 cudnn설치

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
텍스트 마이닝
단어사전 분류 체계: 카테고리 키워드 개념
카테고리 키워드를 잘 선정하고 정의하는 것은 문서 분류 품질 향상에 도움을 줌
카테고리 키워드 선정
  도메인 전문가가 직접: 품질은 우수한데 많은 노력과 시간이 소요
  문헌 참조: 품질은 낮지만 비용과 노력 절감(위키디피아 같은 인터넷매체 활용)
분석 목표 달성을 위해서는
  목표에 부합한 분류체계 구축
  구축된 분류 체계의 개별카테고리 정의
  
  
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
기술통계 함수
  평균: mean(x)
  중앙값: median(x)
  최소값: min(x)
  최대값: max(x)
  범위: range(x)
    최소값 최대값
  중심화 경향 및 분포 요약/통계치?: summary(x)
  퍼짐정도
  분산: var(x)
  표준편차: sd(x)
  확률분포의 비대칭 정도
  왜도: skewness(x)
    install.packages("fBasics") # 왜도, 첨도 분석 가능한 package 설치
	library(fBasics) # package 호출
	hist(mtcars$mpg)
  첨도: kutosis(x)
    관측값이 정규분포보다 뾰족한지의 여부
	3보다 크면 더 뾰족 3보다 작으면 덜뾰족
  기타 함수
  n차 차분: diff(x, lag=n)
    관측값에서 직전 관측값을 뺀거
  순위: rank(x)
    디폴트는 작은값부터 1 부여
	
	
데이터 가공
  read.csv('경로', na.string=c("","NA","#DIV/0!"))
    읽어올때 결측치를 NA로 하여 처리
  위치값 반환: which(x)
  위치값 반환 응용
    정상값 3% 미만 컬럼 제거: x <- x[,-which(colMeans(!is.na(x))<0.03)]
	불필요 컬럼 삭제(컬럼명으로): x <- x[,-which(names(x)=='컬럼명')]
	불필요 컬럼 삭제(컬럼명포함): x <- x[,-grep('포함되있을이름',names(x))]

교차검증과 데이터 전처리
  머신러닝을 학습시키고자 데이터를 트레이닝 데이터와 테스트 데이터로 나눌때 테스트데이터는 트레이닝에 절대로 사용해서 안됨
  하지만 트레이닝 데이터로 in-Sample테스팅을 하면 오류가 작게 나와서 이 트레이닝 데이터를 Out-Of-Sample데이터처럼 나눔
  이런 데이터를 구간별로 나뉘어서 여러번 반복함
  분활 방법
    K-fold(cv): 동일한 사이즈 K개의 파트로 나누어서 순차적으로 적용
	Random Resampling(boot): Bootstrapping을 적용하여 resampling with replacement로 만듦
	Leave One Out(LOOCV): 단 하나의 관측값만 교차검증 용으로 남겨둠. 느림
  Caret(Clasification and Regression Training) 패키지
    전처리 기능: preProcess
	용이한 교차검증 기능: trControl
	데이터 분활 기능: createDataPartition(), createResample() 등
	ML 방법이 다르더라도 동일한 인터페이스 제공: train(), predict()
	혼돈 행렬과 같은 모형 성능 수치 계산: confusionMatrix()
	
	
용어 정리
Bootstrapping: 
  통계학: 가설검증(test)을 하거나 metric(수치??)을 계산하기 전에 random sampling을 적용하는 방법을 일걷음
   ML: 데이터 셋(training set) 내의 데이터 분포가 고르지 않은 경우 
   
데이터 정규화 - scale()
변수값의 분포를 표준화 하는것
데이터 정규화시 변수값의 평균은 0이 되고 분포또한 일정해짐   

문자열 처리 함수
  tolower(), toupper(): 소문자, 대문자 변환
  strsplit(): 문자열 쪼개서 list 반환
  paste(), paste0(): 문자열 병합 후 반환
  sub(), gsub(): 문자열 벡터에서 패턴을 찾아 교체
  grep(), grepl(): 문자열 벡터에서 패턴 유무 알려줌
  nchar(): 문자열에서 문자 개수 카운트
  substr(): 문자열의 일부 가져옴
  
정규표현식
  ^: 시작일치 ^문자
  $: 끝일치 문자$
  []: 문자 클래스 ^[char], ^[0-9]
  [^]: Not 문자 클래스 [^0-9]$
  .: 도트 아무 문자 a..b일경우 accb는 되는데 acb는 안됨 ab도 안되고
  *: 0회 이상 반복 ca*t일경우 ct a(0번반복) cat caat과 같은 상황에서 전부 맞는상황
  +: 1회 이상 반복 ca+t일 경우 ct는 a가 한번도 반복이 안되서 매치 아님
  ?: {0,1}의 의미 ca?t caat는 a가 두번반복됨 cat나 ct는 1번,0번반복해서 매치
  {m} : m회 반복 ca{2}t
  {m,n}: m~n회 반복 ca{1,3}t
  |: or flood|fire
  단축표현
    \\w = [a-zA-Z0-9_]
	\\W = [^a-zA-Z0-9_]
	\\d = [0-9]
	\\D = [^0-9]

자주 사용하는 함수
  summary: 모델링 결과 요약
  sort(data,decreasing=FALSE): 정렬된 값을 보여줌
  order(data,decreasing=FALSE): 정렬된 '위치'값을 보여줌
  
  
  
vif정보량
aic잔차
varimpRF에서 정보의 중요도  