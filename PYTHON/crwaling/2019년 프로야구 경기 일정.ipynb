{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 애플리케이션이 Ajax 통신을 이용하는 경우\n",
    "\n",
    "웹 브라우저가 직접 서버에 요청하게 되면 수신받은 응답결과를 브라우저가 직접 처리하려고 한다.\n",
    "\n",
    "이 때문에 화면이 변경되는 일이 발생하게 된다. \n",
    "\n",
    "만약 개발자가 화면 변경 없이 서버와 통신하고자 한다면(아이디 중복확인 등) Ajax통신을 사용하여 백그라운드에서 통신할 수 있으며 브라우저의 화면은 변경되지 않는다\n",
    "\n",
    "1. 우클릭시 프레임 소스보기가 없는가.\n",
    "2. 페이지 소스보기했을 때 데이터가 없는가.\n",
    "3. 크롬의 개발자 도구에서 Network 탭의 XHR 영역에서 페이지를\n",
    "   이용할 때 마다 통신 기록이 남는가.\n",
    "   \n",
    "만약 위의 조건이 맞는다면 Ajax를 사용하고 있는 것이고 XHR에 나오는 통신 기록이 요청할 주소가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# 한번이라도 저장한적이 있는지..\n",
    "chk = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 입력받아 그 주의 월요일 부터 일요일까지의 날짜\n",
    "# 다음 주의 날짜를 반환하는 함수\n",
    "def getDate(date) :\n",
    "    url = f'https://sports.news.naver.com/schedule/scoreBoard.nhn?date={date}&category=kbo'\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    # print(soup)\n",
    "    # li 태그들을 가져온다.\n",
    "    li_list = soup.select('ul.tab > li')\n",
    "    # print(li_list)\n",
    "    \n",
    "    date_list = []\n",
    "    \n",
    "    # li 태그의 수 만큼 반복한다.\n",
    "    for idx, li_tag in enumerate(li_list) :\n",
    "        # 첫 번째 li 태그라면 그냥 넘어간다.\n",
    "        if idx == 0 :\n",
    "            continue\n",
    "        # a 태그를 추출한다.\n",
    "        a_tag = li_tag.select('a')[0]\n",
    "        # print(a_tag)\n",
    "        # onclick 속성의 값을 가져온다.\n",
    "        onclick = a_tag.attrs['onclick']\n",
    "        # print(onclick)\n",
    "        # 날짜 값을 가져온다.\n",
    "        date_value = onclick.split(\"'\")[1]\n",
    "        # print(date_value)\n",
    "        date_list.append(date_value)\n",
    "        \n",
    "    # print(date_list[-1])\n",
    "    # print(date_list[:-1])\n",
    "    return date_list[:-1], date_list[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 날짜의 프로야구 데이터를 반환하는 함수\n",
    "def getKBOData(now) :\n",
    "    url = f'https://sports.news.naver.com/schedule/scoreBoard.nhn?date={now}&category=kbo'\n",
    "    \n",
    "    # 오류 발생시를 대비해 요청 주소를 기록한다.\n",
    "    with open ('KBOLog.txt', 'at') as fp :\n",
    "        fp.write(url)\n",
    "        fp.write('\\n')\n",
    "        \n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    # 해당 날짜의 경기 데이터를 가지고 있는 ul 태그를 추출한다.    \n",
    "    todaySchedule = soup.select('#todaySchedule')\n",
    "    \n",
    "    if len(todaySchedule) > 0 :\n",
    "        # 내부의 모든 li 태그를 가져온다.\n",
    "        li_list = todaySchedule[0].select('li')\n",
    "        # li 태그 개수만큼 반복한다.\n",
    "        for li_tag in li_list :\n",
    "            # class 속성값을 가져온다.\n",
    "            class_value = li_tag.attrs['class']\n",
    "            # print(class_value)\n",
    "            \n",
    "            data_list = []\n",
    "            \n",
    "            if class_value[0] == 'end' :\n",
    "                data_list.append('경기종료')\n",
    "                data_list.append(now)\n",
    "                # 팀 데이터를 추출한다.\n",
    "                team_tag = li_tag.select('p.vs_team > strong')            \n",
    "                data_list.append(team_tag[1].text.strip())\n",
    "                data_list.append(team_tag[0].text.strip())\n",
    "                # 점수 데이터를 가져온다.\n",
    "                team_score = li_tag.select('strong.vs_num')\n",
    "                data_list.append(team_score[1].text.strip())\n",
    "                data_list.append(team_score[0].text.strip())\n",
    "                # 투수 이름을 가져온다.\n",
    "                team_pitcher = li_tag.select('span.game_info > a')\n",
    "                if len(team_pitcher) > 0 :\n",
    "                    data_list.append(team_pitcher[1].text.strip())\n",
    "                    data_list.append(team_pitcher[0].text.strip())\n",
    "                else :\n",
    "                    data_list.append('모름')\n",
    "                    data_list.append('모름')\n",
    "                    \n",
    "                \n",
    "            elif class_value[0] == 'before_game' :\n",
    "                data_list.append('경기전')\n",
    "                data_list.append(now)\n",
    "                # 팀 데이터를 추출한다.\n",
    "                team_tag = li_tag.select('p.vs_team > strong')            \n",
    "                data_list.append(team_tag[1].text.strip())\n",
    "                data_list.append(team_tag[0].text.strip())\n",
    "                # 점수 데이터를 가져온다.\n",
    "                data_list.append('-1')\n",
    "                data_list.append('-1')\n",
    "                # 투수 이름을 가져온다.\n",
    "                data_list.append('모름')\n",
    "                data_list.append('모름')\n",
    "                \n",
    "            global chk\n",
    "            if chk == False :\n",
    "                chk = True\n",
    "                head_list = ['경기상태', '날짜', '어웨이팀', '홈팀',\n",
    "                             '어웨이점수', '홈점수', '어웨이투수',\n",
    "                             '홈투수']\n",
    "                \n",
    "                \n",
    "                df = pandas.DataFrame([data_list])\n",
    "                df.columns = head_list\n",
    "                df.to_csv('KBO.csv', index=False, encoding='utf-8-sig')\n",
    "            else :\n",
    "                \n",
    "                df = pandas.DataFrame([data_list])\n",
    "                df.to_csv('KBO.csv', index=False, encoding='utf-8-sig', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190311 수집중\n",
      "20190312 수집중\n",
      "20190313 수집중\n",
      "20190314 수집중\n",
      "20190315 수집중\n",
      "20190316 수집중\n",
      "20190317 수집중\n",
      "20190318 수집중\n",
      "20190319 수집중\n",
      "20190320 수집중\n",
      "20190321 수집중\n",
      "20190322 수집중\n",
      "20190323 수집중\n",
      "20190324 수집중\n",
      "20190325 수집중\n",
      "20190326 수집중\n",
      "20190327 수집중\n",
      "20190328 수집중\n",
      "20190329 수집중\n",
      "20190330 수집중\n",
      "20190331 수집중\n",
      "20190401 수집중\n",
      "20190402 수집중\n",
      "20190403 수집중\n",
      "20190404 수집중\n",
      "20190405 수집중\n",
      "20190406 수집중\n",
      "20190407 수집중\n",
      "20190408 수집중\n",
      "20190409 수집중\n",
      "20190410 수집중\n",
      "20190411 수집중\n",
      "20190412 수집중\n",
      "20190413 수집중\n",
      "20190414 수집중\n",
      "20190415 수집중\n",
      "20190416 수집중\n",
      "20190417 수집중\n",
      "20190418 수집중\n",
      "20190419 수집중\n",
      "20190420 수집중\n",
      "20190421 수집중\n",
      "20190422 수집중\n",
      "20190423 수집중\n",
      "20190424 수집중\n",
      "20190425 수집중\n",
      "20190426 수집중\n",
      "20190427 수집중\n",
      "20190428 수집중\n",
      "20190429 수집중\n",
      "20190430 수집중\n",
      "20190501 수집중\n",
      "20190502 수집중\n",
      "20190503 수집중\n",
      "20190504 수집중\n",
      "20190505 수집중\n",
      "20190506 수집중\n",
      "20190507 수집중\n",
      "20190508 수집중\n",
      "20190509 수집중\n",
      "20190510 수집중\n",
      "20190511 수집중\n",
      "20190512 수집중\n",
      "20190513 수집중\n",
      "20190514 수집중\n",
      "20190515 수집중\n",
      "20190516 수집중\n",
      "20190517 수집중\n",
      "20190518 수집중\n",
      "20190519 수집중\n",
      "20190520 수집중\n",
      "20190521 수집중\n",
      "20190522 수집중\n",
      "20190523 수집중\n",
      "20190524 수집중\n",
      "20190525 수집중\n",
      "20190526 수집중\n",
      "20190527 수집중\n",
      "20190528 수집중\n",
      "20190529 수집중\n",
      "20190530 수집중\n",
      "20190531 수집중\n",
      "20190601 수집중\n",
      "20190602 수집중\n",
      "20190603 수집중\n",
      "20190604 수집중\n",
      "20190605 수집중\n",
      "20190606 수집중\n",
      "20190607 수집중\n",
      "20190608 수집중\n",
      "20190609 수집중\n",
      "20190610 수집중\n",
      "20190611 수집중\n",
      "20190612 수집중\n",
      "20190613 수집중\n",
      "20190614 수집중\n",
      "20190615 수집중\n",
      "20190616 수집중\n",
      "20190617 수집중\n",
      "20190618 수집중\n",
      "20190619 수집중\n",
      "20190620 수집중\n",
      "20190621 수집중\n",
      "20190622 수집중\n",
      "20190623 수집중\n",
      "20190624 수집중\n",
      "20190625 수집중\n",
      "20190626 수집중\n",
      "20190627 수집중\n",
      "20190628 수집중\n",
      "20190629 수집중\n",
      "20190630 수집중\n",
      "20190701 수집중\n",
      "20190702 수집중\n",
      "20190703 수집중\n",
      "20190704 수집중\n",
      "20190705 수집중\n",
      "20190706 수집중\n",
      "20190707 수집중\n",
      "20190708 수집중\n",
      "20190709 수집중\n",
      "20190710 수집중\n",
      "20190711 수집중\n",
      "20190712 수집중\n",
      "20190713 수집중\n",
      "20190714 수집중\n",
      "20190715 수집중\n",
      "20190716 수집중\n",
      "20190717 수집중\n",
      "20190718 수집중\n",
      "20190719 수집중\n",
      "20190720 수집중\n",
      "20190721 수집중\n",
      "20190722 수집중\n",
      "20190723 수집중\n",
      "20190724 수집중\n",
      "20190725 수집중\n",
      "20190726 수집중\n",
      "20190727 수집중\n",
      "20190728 수집중\n",
      "20190729 수집중\n",
      "20190730 수집중\n",
      "20190731 수집중\n",
      "20190801 수집중\n",
      "20190802 수집중\n",
      "20190803 수집중\n",
      "20190804 수집중\n",
      "20190805 수집중\n",
      "20190806 수집중\n",
      "20190807 수집중\n",
      "20190808 수집중\n",
      "20190809 수집중\n",
      "20190810 수집중\n",
      "20190811 수집중\n",
      "20190812 수집중\n",
      "20190813 수집중\n",
      "20190814 수집중\n",
      "20190815 수집중\n",
      "20190816 수집중\n",
      "20190817 수집중\n",
      "20190818 수집중\n",
      "20190819 수집중\n",
      "20190820 수집중\n",
      "20190821 수집중\n",
      "20190822 수집중\n",
      "20190823 수집중\n",
      "20190824 수집중\n",
      "20190825 수집중\n",
      "20190826 수집중\n",
      "20190827 수집중\n",
      "20190828 수집중\n",
      "20190829 수집중\n",
      "20190830 수집중\n",
      "20190831 수집중\n",
      "20190901 수집중\n",
      "20190902 수집중\n",
      "20190903 수집중\n",
      "20190904 수집중\n",
      "20190905 수집중\n",
      "20190906 수집중\n",
      "20190907 수집중\n",
      "20190908 수집중\n",
      "20190909 수집중\n",
      "20190910 수집중\n",
      "20190911 수집중\n",
      "20190912 수집중\n",
      "20190913 수집중\n",
      "20190914 수집중\n",
      "20190915 수집중\n",
      "수집완료\n"
     ]
    }
   ],
   "source": [
    "chk = False\n",
    "\n",
    "current_date = '20190311'\n",
    "\n",
    "# print(date_list)\n",
    "# print(next_week)\n",
    "# 해당 주의 날짜 수만큼 반복한다.\n",
    "while True:\n",
    "    date_list, next_week = getDate(current_date)\n",
    "    for now in date_list :\n",
    "        print(f'{now} 수집중')\n",
    "        getKBOData(now)\n",
    "    if len(next_week) == 0:\n",
    "        break\n",
    "    else :\n",
    "        current_date = next_week\n",
    "print('수집완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
