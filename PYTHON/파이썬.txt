파이썬 관련
  if __name__ == "__main__"를 사용하는 이유는 import하여 사용할때는 내부에 즉시실행함수들을 사용하지 않고
  정의되있는 함수를 사용하기 위해 사용함. 만약 test.py를 단독으로 사용하고 싶을때는 test.py의 if __name__ == "__main__"에 작성해놓은
  코드가 실행되지만 import하여 부를때는 실행되지 않는다
  그 이유는 파이썬의 __name__ 변수는 호출 될때 __main__으로 호출되지만 import시에는 파일명으로 호출되기 때문이다.

with 구문
  보통 파일의 작업흐름은 open()으로 파일을 열고 close()로 수행해야함. 아님 자료 날라갈수 있음
  그래서 try ~ finally와 세트로 사용해야하는데 넘모 귀찮자너. 그래서 with를 씀
  타입: o(open), r(write), a(append), ob(open binary), rb(write binary), ab(append binary)
  with open("파일명","타입") as 얠뭐로부를건지
	f.write('파이썬으로 파일을 작성하고 있습니다.')
	pickle.dump(저장할자료변수,얠뭐로부를건지)
  
pickle
  사용했던 데이터를 저장할 수 있음
  with open("example.pickle","wb") as f
	pickle.dump(학습된변수명,f)	#저장할 때
	new_open = pickle.load(f)		#열 때
  꺼내온 모형으로 시험할때
  new_open.predict(시험할데이터)

virtualenv
  보통 파이썬으로 작업 시 virtualenv라는 가상 환경을 사용함
  그 이유는 한 컴퓨터에서 여러 프로젝트를 작업할 때 파이썬 패키지의 의존성이 충돌하지 않도록 관리해주기 때문
  어떤 패키지 설치시 의존성 때문에 같이 설치되는 패키지들이 다른 프로젝트에서 설치한 같은 패키지들을 덮어쓰지 않음
  sudo apt-get install python-pip python-dev python-virtualenv # 우분투/리눅스 64빗
  pip install --upgrade virtualenv # 윈도우
  virtualenv --system-stie-packages ~/tensorflow #~/tensorflow 디렉토리에 virtualenv환경을 만듦
  source ~/tensorflow/bin/active #bash사용시 virtualenv활성화. csh사용하면 active.csh

Numpy
  과학 계산과 데이터 다루기를 용이하게 해주는 패키지
  고차원 배열을 객체로 제공하며 관련 메소드를 제공
  메소드의 연산속도는 최적화가 되어있음(빠름)
  연산의 벡터화 제공 -> 코딩하기 편리하며 가독성 증대
  파이썬 리스트의 차이점
    Numpy는 배열의 크기가 정해져 있음: 크기를 변경하는 경우 새로운 객체가 생성됨
	Numpy 배열 개개 원소의 자료형은 일치되어 있어야 함
	파이썬 리스트가 제공하지 않는 많은 수학연산 제공
	다른 패키지에서도 Numpy 배열을 기초 자료형으로 사용함
  import numpy
  기본적으로 변수생성후 변수 박아넣으면 얕은복사로 인해 메모리를 공유하니 변수명.copy()를 해줘야됨
  numpy.arange(): 배열 생성 함수
    arange(10): 0 ~ 9
	arange(10,20): 10 ~ 20
	arange(10,20,3): 10 13 16 19
    생성후 변수.size하면 갯수, 변수.shape는 어떤 형태로 되어있는지 ex(3x3행렬은 3L,3L), 변수.ndim은 차원의 수
  numpy.linspace(0,10,5): 0,2.5,5 ... 10 0과 10사이 5개구간나눠 숫자나옴
  numpy.zeros()
    zeros(10): 10개의 0
	zeros((3,4)): 3 x 4의 0들어간 행렬
	zeros(5,dtype='int64'): 자료형 명시 array([0,0,0,0,0],dtype=int64)리턴됨
  numpy.ones((2,3),dtype='int_'):
  변수.reshape(x, y): x * y 모양의 2D행렬로 바꾸어 보여줌(비항구적)
    *주의* reshape후 원본 변수의 값을 바꾸면 reshape한 변수의 값도 변화하기 때문에 copy()써서 복사해야됨
	.reshape(1,-1)하나의 행 여러개의 열
	.reshape(-1,1)하나의 열 여러개의 행
	.reshape(n1,n2) n1개의 행 n2개의 열
	인자값이 -1 일경우 알아서 처리해줌
  변수.shape=(x,y): x * y 모양의 2D행렬로 바꾸어 보여줌(항구적)
  변수 = numpy.append(변수, [[x],[y]], axis=0 or 1): 변수에 x,y값을 0일때는 행으로 추가 1일때는 열로추가함
  변수[((변수%5)==0) & (변수>0)]: 0이상이고 5로 나누어 떨어지는수 반환(검색)
  numpy.delete 배열 삭제
    delete(변수,(0,1,2)): 변수에서 0,1,2삭제 2차원배열이였으면 1차원배열되서 반환
	delete(변수,0,axis=0|1): 변수에서 0번째 axis가 0일때는 행전체 1일때는 열전체를 삭제함
  통계함수 변수.함수에서 변수.은 생략했음. 여기 나온거 외에도 많으니 다른것들은 문서참조
    sum(): 합계 / mean(): 평균 / std(): 표준편차 / var(): 분산 / cumsum(): 누적배열 이외것들은 
  dot 연산자
    x = numpy.array([1,3,5])
	y = numpy.array([2,4,6]) 일때
	개개원소를 서로 곱하고 누적을 구한 값임
	np.sum(x*y) == np.dot(x,y) == x.dot(y)
  numpy.random
    random((x,y)): 0과 1사이 균등분포 랜덤 행렬
	randn(x,y): 정규분포 랜덤 행렬
  numpy.diag([1,2,3]): 대각행렬 np.diag(변수)하면 대각선상 원소 나옴
  numpy.transpose(변수): x*y행렬을 y*x행렬로 변환
선형대수학 초간단
  행렬의 곱셈은 가능하지만 나눗셈은 불가능함. 그러므로 역행렬을 구해 곱해줌
  역행렬은 행렬이 정사각행렬이여야 함
  numpy.linalg.inv(변수): 행렬을 역행렬로 변환함. 이걸 원래 변수와 곱하면 array([[1., 0.],[0., 1.]])가 나옴
  [[x],[y]] * [[n1_1,n1_2],[n2_1,n2_2]] = [[S1],[S2]] 일때, [[n1_1,n1_2],[n2_1,n2_2]]의 역행렬을 구해[[S1],[S2]]와 곱해주면 x,y값 나옴

Pandas
  파이썬 안에서 데이터 가공목적으로 사용함
  Numpy 패키지를 바탕으로 만들어짐
  Series와 DataFrame 객체를 다루는 목적으로 특화
  통계, 결측치 처리, 시각화등 다양한 기능이 있음
  시작
    import pandas
    import numpy 
  Series
    1차원 배열과 유사
	값(value) + 인덱스(index) = 시리즈 클래스(Series)
	index속성이 있어 인덱싱 목적으로 사용
	벡터연산도 지원함
	s = pandas.Series(data=[list|dict|numpy.ndarray],index=[배열같은거]):
	  dictionary일 경우 key가 index value가 value로 변환됨. 기본값으로는 index가 0 1 2...
	s[1]: 1번째 값 리턴(0부터 시작)
	s[2:4]: 2,3번째 값 리턴
	s[['a','b']]: index가 a,b인값 리턴
	서로다른 시리즈끼리 연산시 index값을 기준으로 연산하기때문에 서로의 index가 없으면 NaN을 반환함
	s.sum(): s의 모든값 더함
	s.mean(): s의 평균
	s.median(): s의 중앙값
	s.max(): s의 최대값
	s.std(): s의 표준편차
  dataframe
    검색시 주의점: 검색조건이 하나일경우 array를 반환하지만 여러개일경우 dataframe을 반환함
    .shape: 행, 열 반환
	.size: 행*열 반환
	.ndim: Series면 1반환, dataframe이면 2반환
    .info(): 컬럼별 정보 요약
	.describe(): 정보 요약
	.head([num]): num만큼의 행반환
	.tail([num]): 뒤에서 num만큼의 행반환
	.columns: 열 이름 반환
	.columns = [array]: 열 이름 변경
	.[[컬럼명]]: 컬럼명 반환
	.loc[:,[컬럼명1,컬럼명2...]]: 컬럼명 반환
	.loc[:,(header==컬럼명1)|(header==컬럼명2)...]]: header = df.columns사전작업 필요. 컬럼명 반환
	.loc[:,[num1,num2...]]: 컬럼윗치값 반환 bool써도 됨
	.loc[x:y]: x부터 y까지의 행반환
	.iloc[x:y]: x부터 y-1까지의 행반환
	.drop(columns=[컬럼명1,컬럼명2...]): 컬럼명들을 제외한 행열반환
	.loc[:, (header!='컬럼명1') & (header!='컬럼명2')]: 컬럼명들을 제외한 행열반환
	df[(df.컬럼명1 == 변수) & df.컬럼명2 == 변수)]: 특정 컬럼명의 값이 변수인것들만 가져옴
	df[새로운컬럼명] = 변수: 새로운 컬럼 추가
	df.drop(컬럼명,axis=1,inplace=True|False): inplace가 True면 진짜 삭제하고 행 반환 False일때는 뭐하냐. axis가 뭐하는 앤지는 몰라
	pd.read_csv('파일명.csv',encoding='latin1',header='infer'): csv 읽을때
	df.to_csv('파일명.csv',index=True|False): csv 파일로 반환
	pd.read_excel('파일명.xlsx', sheet_name='Sheet1'): excel 읽을때
	df.to_excel('파일명.xlsx',sheet_name='NewSheet',index=False): excel로 내보낼때
	신규생성
	  data = {컬럼명1:[값들], 컬럼명2:[값들] ... }
	  df = pd.DataFrame(data)
	pd.merge(df1,df2,on='기준컬럼명'): df1과 df2의 기준컬럼명으로 합침. 일치하지않으면 제외함. inner join
	pd.merge(df1,df2,left_on='df1기준컬럼명',right_on='df2기준컬럼명',how=[inner|left|right|outer]])
		how가 inner일 때: df1과 df2의 기준컬럼명으로 합침. 일치하지않으면 제외함
		how가 left일 때: df1과 df2의 기준컬럼명으로 합침. 일치하지않으면 df2의 데이터는 제외함
		how가 right일 때: df1과 df2의 기준컬럼명으로 합침. 일치하지않으면 df1의 데이터는 제외함
		how가 outer일 때: df1과 df2의 기준컬럼명으로 합침. 좌우 결측치 상관없이 합침
	df.Species.value_counts() dataframe에 대한 통계
  통계관련
	sum(): 합계 axis[0|1] 옵션추가하면 0은 열 1은 행 따라 더함
	mean(axis=0,skipna=False): 열평균을 구하는데 NA무시 안함
	df.describe(): 사분위수 등 기술통계 요약을 보여줌
	count(): axis[0|1] 옵션추가하면 0은 열 1은 행 따라 갯수 셈. NA가 아닌것만
	df.A.corr(df.B): A와 B컬럼간의 상관계수 
	df.corr(): 상관계수 행렬 계산. 시각화 하려면 sns.heatmap(df.corr(),cmap='coolwarm')
	corrwith(df.A): A와 나머지 변수사이의 상관계수
	pd.crosstab(df.A, df.B): 분할표
  결측치(NA) 관련
	df.isnull(): NA 위치에는 True
	(df.isnull()).sum(axis=0): 걸럼별 결측치 계수
	(df.isnull()).mean(axis=0): 컬럼 별 결측치 비중
	df.dropna(axis=0): NA가 포함된 행은 drop
	df.dropna(axis=1): NA가 포함된 열은 drop
	df.dropna(axis=0,thresh=3): 최소 3개 이상 정상값이 있는 행은 제외하고 drop
	df.fillna(value=0): 결측치를 0으로 채워넣음
  멀티인덱스
    index를 그룹으로 묶어서 사용이 가능함
	zipped_index = list(zip(ar1,ar2 ... ))
	m_index = pd.MultiIndex.from_tuples(m_index))
	pd.DataFrame(data=[data], index=m_index)
	검색하려면 맨 처음 인덱스 기준으로 df.loc[index1].lod[index2]... 이런식으로
  그룹연산
	멀티인덱스로 나옴
	df.groupby(['col1','col2'...])['col1','col2'...].func()
  df.apply(사용자 지정 함수 ex)lambda x: x/100): for loop와 비슷함
  df.sort_values([변수1,변수2...],ascending=[bool|bool...]): 정렬함 첫번째 인자로는 컬럼 두번째 asecending은 정렬기준 기본값 True 오름차순 정렬
  명목형 변수
	df[검색조건].unique(): 고유한 값 반환
	df[검색조건].nunique(): 유형의 가지수
	df[검색조건].value_counts(): 도수 분포표
  피보팅
    pd.pivot_table(df										# 데이터
					, index=[col1,col2...]						# 인덱스
					, columns=[col1,col2...]					# 컬럼. 명목형 변수가 들어감
					, values=[col1,col2...]					# 컬럼별 들어갈 값
					, aggfunc={col1:func,col2:func2...}	# 사용할 함수, np.붙여줘야됨
					, fill_value=0)							# 결측치가 나올경우 채울 값

시각화 패키지 matplotlib
  pyplot
    import matplotlib.pyplot as plt
	import numpy as np
	plt
	  .bar(x,y,bins=[num, 빈도수 표현], color='색상'): 바차트로 표현
	  .hist(x,bins=[num], color='색상', density=[True|False ,비율|수치]): 히스토그램으로 표현
	  .boxplot([x,y,z],vert=[True|False ,수평|수직],labels=[변수1,변수2...]): 박스플롯으로 표현
	  .scatter(x,y,c='색상',marker='기호',alpha='투명도'): 산점도로 표현함
	  .plot(x,y,color='색상',linestyle=[별도첨부],marker=[별도첨부]
			,markersize=[num],markerfacecolor=[색상],markeredgecolor=[색상],markeredgewidth=[num]
			,linewidth=[num,굵기],alpha=[0~1,투명도]): 곡선그래프로 표기
		linestyle 종류 : none 라인없음 | : 점선 | -- 단속선 | -. 선과 점 | - 연속선 | steps 꺾은선
		marker 종류 : . 점 | , 픽셀 | o 원 | ^ 삼각형 | v 역삼각형 | s 사각형 | * 별표 | + 플러스 | x 엑스 | D 다이아몬드 | p 정오각형
	  .xlim(범위 ~ 범위): x축 범위
	  .ylim(범위 ~ 범위): y축 범위
	  .xlabel('x축 이름')
	  .ylabel('y축 이름')
	  .title('차트 제목')
	  .show(): 차트를 보여줌
	객체지향형 시각화
	  단일시각화일 경우
	  fig = plt.figure([figsize=([num],[num]), DPI=[num]]): figsize는 가로, 세로 크기, DPI는 해상도
	  axes = fig.add_axes([[num],[num],[num],[num]]): 화면 비율임. 차례대로 Left, Bottom, Width, Height
	  axes.([plot|bar|hist|boxplot]: 옵션은 위에 참고
	  axes.set_[x|y]label('이름'): x|y축 이름 설정
	  axes.set_title('이름'): 그래프 이름 설정
	  다중시각화일 경우
	  fig, axes = plt.subplots(nrows=[num], ncols=[num], figsize=([num],[num])): fig와 axes동시에 선언
	  axes[[num1],[num2]].옵션: num1행 num2열 그래프 설정
	  plt.tight_layout(): 서로 겹치는 현상을 피함
	  fig.savefig('파일명'): 그래프 이미지 출력
	  
통계 관련 함수
  import scipy.stats as st 으로 사용함
  이산확률분포 binom( True | False )
	st.binom.cdf(n번나올확률,시행횟수,성공확률): 확률분포
	st.binom.ppf(0~1,시행횟수,성공확률): 분위수
	st.binom.cdf(0~시행횟수,시행횟수,성공확률): 누적확률
	
통

시각화를 위한 Seaborn패키지
  import seaborn as sns
  •내장데이터를제공한다:load_dataset.
  •기본시각화유형:distplot,jointplot,kdeplot,rugplot,barplot,countplot,등.
  •다중행렬시각화유형:pairplot,PairGrid,FacetGrid,등.
  •회귀선추가기능:lmplot,jointplot,등.
  •2D특수시각화:heatmap,clustermap,등.
  •기본시각화의변형:violinplot,swarmplot,stripplot,등.
  함수들
    sns.distplot(데이터, kde=Boolean, rug=Boolean, bins=빈도수int, color='색상'): 히스토그램
	  kde: 선으로 그래프 그려줌
	  rug: 바닥에 선 깔아줌 뭔 의미인지는 모름
	sns.kdeplot(데이터, color='색상'): 선그래프
	sns.jointplot(x='x축컬럼', y='y축컬럼', data=데이터, color='색상', kind='표현방식'): 산점도
	  kind종류: scatter 산점도 | reg 기울기와 산점도 | hex 육각형 | kde 등고선 더많은 유형은 사이트 참조
	sns.barplot(x='x축컬럼', y='y축컬럼', data=데이터, notch=Boolean True면 홀쭉? 뭔표시여): 막대그림. x y 바뀌면 그래프 수평되서 나옴
	sns.countplot(x='x축컬럼', data=데이터, hue='추가할컬럼. 있으면 분할표로 표시됨', palette='그래프 색상, 여러종류있으니 인터넷 참고'): 도수분포표의 막대그림
	sns.violinplot(x='x축컬럼', y='y축컬럼', data=데이터, palette='그래프 색상'): 바이올린 그림으로 표현
	sns.stripplot(x='x축컬럼', y='y축컬럼', data=데이터): boxplot같이 표현한 산점도
	sns.swarmplot(x='x축컬럼', y='y축컬럼', data=데이터): stripplot같은데 옆으로 퍼져서 분포도 표현한 산점도같은거
	sns.pairplot(데이터, hue='컬럼명'): 산점도 행렬
	같이 표현
	  sns.violinplot(x='x축컬럼', y='y축컬럼', data=데이터)
	  sns.swarmplot(x='x축컬럼', y='y축컬럼', data=데이터)
	  위처럼 같이 쓰면 한 그림에 그래프가 같이 표시됨
  모듈3참조
  

	
병합
  np.concatenate([데이터1, 데이터2],axis=1)  axis 0행으로할껀지 1이면 컬럼으로할껀지
  
문자열 관련함수
x.lstrip() 왼쪽 공백 제거
x.rstrip() 오른쪽 공백 제거
x.strip() 양쪽 공백 제거
x.replace(str1, str2) 문자열 교체str1->str2
x.count(str) 문자 갯수 세기
x.find(str) 위치 반환
x.index(str)